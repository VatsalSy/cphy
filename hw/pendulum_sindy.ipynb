{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90ecb153",
   "metadata": {},
   "source": [
    "# Numerical integration and extinction rates in large random ecosystems\n",
    "\n",
    "Requirements\n",
    "+ matplotlib\n",
    "+ numpy\n",
    "+ scipy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e186f0f",
   "metadata": {
    "tags": [
     "no-pdf"
    ]
   },
   "source": [
    "**A note on cloud-hosted notebooks.** If you are running a notebook on a cloud provider, such as Google Colab or CodeOcean, remember to save your work frequently. Cloud notebooks will occasionally restart after a fixed duration, crash, or prolonged inactivity, requiring you to re-run code.\n",
    "\n",
    "<!-- [Click here to open this notebook in Colab](https://colab.research.google.com/github/williamgilpin/cphy/blob/main/hw/lotka_volterra.ipynb) -->\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/williamgilpin/cphy/blob/main/hw/pendulum_sindy.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6290f3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142e21e",
   "metadata": {},
   "source": [
    "<!-- <img src=\"../resources/lynx_tom_bech_ccby3.jpeg\" style=\"max-width:40%; height:auto;\"> -->\n",
    "\n",
    "<!-- *Image from Tom Bech, CC BY 3.0 <https://creativecommons.org/licenses/by/3.0>, via Wikimedia Commons* -->\n",
    "\n",
    "## Learning equations from data\n",
    "\n",
    "The growing field of scientific machine learning aims to discover interpretable and predictable models of physical systems directly from observations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6d56e",
   "metadata": {},
   "source": [
    "### To Do\n",
    "\n",
    "*Please complete the following tasks and answer the included questions. You can edit a Markdown cell in Jupyter by double-clicking on it. To return the cell to its formatted form, press `[Shift]+[Enter]`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0052177",
   "metadata": {},
   "source": [
    "1. Implement SINDy with a library of candidate terms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bede51",
   "metadata": {},
   "source": [
    "```\n",
    "    Your Answer: complete the code below\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6475e419",
   "metadata": {},
   "source": [
    "2. Try varying the size of the candidate library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54cabcc",
   "metadata": {},
   "source": [
    "```\n",
    "    Your Answer: complete the code below\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a536505",
   "metadata": {},
   "source": [
    "3. Try modifying your candidate library to include a term that describes the damping of the pendulum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28286936",
   "metadata": {},
   "source": [
    "```\n",
    "    Your Answer: \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edabacb6",
   "metadata": {},
   "source": [
    "4.  The phenomenon you are observing is known as multicollinearity, and it occurs when there is a degeneracy among candidate models for a given dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33e58d2",
   "metadata": {},
   "source": [
    "```\n",
    "    Your Answer: \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7b6def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "class SINDyLasso:\n",
    "    \"\"\"\n",
    "    Minimal SINDy using scikit-learn's Lasso for sparse regression.\n",
    "\n",
    "    Args:\n",
    "        poly_order (int): Maximum total degree of polynomial features (>=1).\n",
    "        alpha (float): L1 regularization strength passed to sklearn.linear_model.Lasso.\n",
    "        include_bias (bool): Include constant feature (1).\n",
    "        max_iter (int): Max iterations for Lasso solver.\n",
    "        tol (float): Tolerance for Lasso convergence.\n",
    "\n",
    "    Attributes:\n",
    "        coef_ (ndarray): Coefficient matrix (n_features x n_states).\n",
    "        feature_names_ (list[str]): Names of library features, length n_features.\n",
    "        poly_order (int)\n",
    "        alpha (float)\n",
    "        include_bias (bool)\n",
    "        max_iter (int)\n",
    "        tol (float)\n",
    "    \"\"\"\n",
    "    def __init__(self, poly_order=3, alpha=1e-2, include_bias=True, max_iter=10000, tol=1e-6):\n",
    "        self.poly_order = int(poly_order)\n",
    "        self.alpha = float(alpha)\n",
    "        self.include_bias = bool(include_bias)\n",
    "        self.max_iter = int(max_iter)\n",
    "        self.tol = float(tol)\n",
    "        self.coef_ = None\n",
    "        self.feature_names_ = None\n",
    "\n",
    "    def _poly_library(self, X):\n",
    "        \"\"\"Polynomial library up to poly_order (with optional bias).\"\"\"\n",
    "        n, d = X.shape\n",
    "        cols, names = [], []\n",
    "        if self.include_bias:\n",
    "            cols.append(np.ones((n, 1)))\n",
    "            names.append(\"1\")\n",
    "        cols.append(X)\n",
    "        names += [f\"x{i+1}\" for i in range(d)]\n",
    "        for deg in range(2, self.poly_order + 1):\n",
    "            for idxs in combinations_with_replacement(range(d), deg):\n",
    "                cols.append(np.prod(X[:, idxs], axis=1, keepdims=True))\n",
    "                names.append(\"*\".join([f\"x{j+1}\" for j in idxs]))\n",
    "        Theta = np.hstack(cols)\n",
    "        return Theta, names\n",
    "\n",
    "    def _finite_difference(self, X, t):\n",
    "        \"\"\"Use np.gradient with uniform dt; second-order edges.\"\"\"\n",
    "        t = np.asarray(t)\n",
    "        if t.ndim != 1 or len(t) != len(X):\n",
    "            raise ValueError(\"t must be 1D and match X length.\")\n",
    "        dt = np.diff(t)\n",
    "        if not np.allclose(dt, dt[0]):\n",
    "            raise ValueError(\"This minimal version requires uniform sampling in t.\")\n",
    "        dXdt = np.gradient(np.asarray(X, float), dt[0], axis=0, edge_order=2)\n",
    "        return dXdt\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fit sparse RHS x_dot = Θ(X) Ξ via independent Lasso regressions per state.\n",
    "\n",
    "        Args:\n",
    "            X (ndarray): (n_samples, n_states) time series.\n",
    "\n",
    "        Returns:\n",
    "            self\n",
    "        \"\"\"\n",
    "        X = np.asarray(X, float)\n",
    "\n",
    "        dXdt = self._finite_difference(X, t)\n",
    "        Theta, names = self._poly_library(X)\n",
    "        n_states = X.shape[1]\n",
    "        Xi = np.zeros((Theta.shape[1], n_states))\n",
    "        for k in range(n_states):\n",
    "            model = Lasso(alpha=self.alpha, fit_intercept=False, max_iter=self.max_iter, tol=self.tol)\n",
    "            model.fit(Theta, dXdt[:, k])\n",
    "            Xi[:, k] = model.coef_\n",
    "\n",
    "        self.coef_ = Xi\n",
    "        self.feature_names_ = names\n",
    "        return self\n",
    "\n",
    "    def predict_rhs(self, X):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            X (ndarray): (n_samples, n_states)\n",
    "\n",
    "        Returns:\n",
    "            ndarray: (n_samples, n_states) predicted time derivatives.\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError(\"Call fit() first.\")\n",
    "        Theta, _ = self._poly_library(np.asarray(X, float))\n",
    "        return Theta @ self.coef_\n",
    "\n",
    "    def print_model(self):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            list[str]: Human-readable RHS for each state.\n",
    "        \"\"\"\n",
    "        if self.coef_ is None:\n",
    "            raise RuntimeError(\"Call fit() first.\")\n",
    "        eqs = []\n",
    "        for k in range(self.coef_.shape[1]):\n",
    "            terms = [f\"{c:.6g}*{n}\" for c, n in zip(self.coef_[:, k], self.feature_names_) if abs(c) > 0]\n",
    "            rhs = \" + \".join(terms) if terms else \"0\"\n",
    "            eqs.append(f\"dx{k+1}/dt = {rhs}\")\n",
    "        return eqs\n",
    "\n",
    "\n",
    "# Example usage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdec9e4",
   "metadata": {},
   "source": [
    "### Test and use your code\n",
    "\n",
    "+ You don't need to write any code below, these cells are just to confirm that everything is working and to play with your implementation\n",
    "+ If you are working from a local fork of the entire course, then you already have access to the solutions. In this case, make sure to `git pull` to make sure that you are up-to-date (save your work first).\n",
    "+ If you are working from a single downloaded notebook, or are working in Google Colab, then you will need to manually download the solutions file from the course repository. The lines below will do this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19acf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "# Check if the \"solutions\" directory exists. If not, create it and download the solution file\n",
    "if not os.path.exists('solutions'):\n",
    "    os.makedirs('solutions')\n",
    "else:\n",
    "    print('Directory \"solutions\" already exists. Skipping creation.')\n",
    "\n",
    "# Now download the solution file into the directory we just created\n",
    "url = 'https://raw.githubusercontent.com/williamgilpin/cphy/main/hw/solutions/allencahn_spectral.py'\n",
    "response = requests.get(url)\n",
    "file_path = os.path.join('solutions', 'sandpile.py')\n",
    "with open(file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(f'File saved to {file_path}')\n",
    "# Now download the solution file into the directory we just created\n",
    "url = 'https://raw.githubusercontent.com/williamgilpin/cphy/main/hw/solutions/allencahn.py'\n",
    "response = requests.get(url)\n",
    "file_path = os.path.join('solutions', 'sandpile.py')\n",
    "with open(file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "print(f'File saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f133b96e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef7cd77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169637b0-6a6e-4e14-852a-d6115f698300",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
