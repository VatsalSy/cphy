{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d50c687",
   "metadata": {},
   "source": [
    "# Diffusion models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc1a99",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "<!-- [Click here to open this notebook in Colab](https://colab.research.google.com/github/williamgilpin/cphy/blob/main/talks/svd_decomp.ipynb) -->\n",
    "Open this notebook in Google Colab: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/williamgilpin/cphy/blob/main/talks/svd_decomp.ipynb)\n",
    "\n",
    "We start by importing the necessary Python packages.\n",
    "<!-- *This notebook created by William Gilpin. Consult the [course website](https://www.wgilpin.com/cphy) for all content and [GitHub repository](https://github.com/williamgilpin/cphy) for raw files and runnable online code.* --"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ee03d2d-906b-4dee-aee1-b48f2a17a887",
   "metadata": {
    "tags": [
     "remove-cell-pdf"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Wipe all outputs from this notebook\n",
    "from IPython.display import Image, clear_output, display\n",
    "clear_output(True)\n",
    "\n",
    "# Import local plotting functions and in-notebook display functions\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113c72e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimal DDPM on MNIST (pure PyTorch, ~120 lines)\n",
    "import math, torch, torch.nn as nn, torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "# ----------------------- tiny UNet -----------------------\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, 3, padding=1), nn.GroupNorm(8, c_out), nn.SiLU(),\n",
    "            nn.Conv2d(c_out, c_out, 3, padding=1), nn.GroupNorm(8, c_out), nn.SiLU(),\n",
    "        )\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "class TinyUNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_steps (int): Number of diffusion steps for sinusoidal time embedding.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_steps=200):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            nn.Linear(64, 128), nn.SiLU(),\n",
    "            nn.Linear(128, 128),\n",
    "        )\n",
    "        def tembed(t, dim=64):\n",
    "            half = dim//2\n",
    "            freqs = torch.exp(torch.linspace(0, math.log(10000), half, device=t.device))\n",
    "            args = t[:,None]/n_steps\n",
    "            emb = torch.cat([torch.sin(args*freqs), torch.cos(args*freqs)], dim=-1)\n",
    "            return emb\n",
    "        self.tembed = tembed\n",
    "\n",
    "        self.inp  = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.b1   = Block(32, 64)\n",
    "        self.down = nn.Conv2d(64, 64, 4, 2, 1)\n",
    "        self.b2   = Block(64, 128)\n",
    "        self.mid  = Block(128, 128)\n",
    "        self.up   = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
    "        self.b3   = Block(64+64, 64)\n",
    "        self.out  = nn.Conv2d(64, 1, 1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (Tensor): Noisy images (N,1,28,28).\n",
    "            t (Tensor): Integer timesteps (N,).\n",
    "        Returns:\n",
    "            Tensor: Predicted noise ε_θ(x_t,t) with same shape as x.\n",
    "        \"\"\"\n",
    "        temb = self.time_mlp(self.tembed(t))[:, :, None, None]\n",
    "        h0 = F.silu(self.inp(x))\n",
    "        h1 = self.b1(h0 + temb)\n",
    "        h2 = self.down(h1)\n",
    "        h3 = self.b2(h2 + temb)\n",
    "        m  = self.mid(h3 + temb)\n",
    "        u  = self.up(m)\n",
    "        u  = self.b3(torch.cat([u, h1], 1) + temb)\n",
    "        return self.out(u)\n",
    "\n",
    "# ----------------------- diffusion utils -----------------------\n",
    "class Diffusion:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        n_steps (int): Number of diffusion steps.\n",
    "        beta_start (float): Start of linear beta schedule.\n",
    "        beta_end (float): End of linear beta schedule.\n",
    "        device (str): 'cuda' or 'cpu'.\n",
    "    Attributes:\n",
    "        betas (Tensor): β_t schedule.\n",
    "        alphas_cumprod (Tensor): ∏_{s<=t} (1-β_s).\n",
    "        alphas_cumprod_prev (Tensor): ∏_{s<=t-1} (1-β_s).\n",
    "        sqrt_alphas_cumprod (Tensor)\n",
    "        sqrt_one_minus_alphas_cumprod (Tensor)\n",
    "        posterior_variance (Tensor): q(x_{t-1}|x_t,x_0) variance.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_steps=200, beta_start=1e-4, beta_end=0.02, device=\"cpu\"):\n",
    "        self.device = device\n",
    "        self.n_steps = n_steps\n",
    "        self.betas = torch.linspace(beta_start, beta_end, n_steps, device=device)\n",
    "        alphas = 1.0 - self.betas\n",
    "        self.alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        self.alphas_cumprod_prev = torch.cat([torch.tensor([1.0], device=device), self.alphas_cumprod[:-1]])\n",
    "        self.sqrt_alphas_cumprod = torch.sqrt(self.alphas_cumprod)\n",
    "        self.sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - self.alphas_cumprod)\n",
    "        self.posterior_variance = self.betas * (1.0 - self.alphas_cumprod_prev) / (1.0 - self.alphas_cumprod)\n",
    "\n",
    "    def q_sample(self, x0, t, noise=None):\n",
    "        \"\"\"Forward diffusion q(x_t|x_0): add noise at step t.\"\"\"\n",
    "        if noise is None: noise = torch.randn_like(x0)\n",
    "        s1 = self.index(self.sqrt_alphas_cumprod, t, x0.shape)\n",
    "        s2 = self.index(self.sqrt_one_minus_alphas_cumprod, t, x0.shape)\n",
    "        return s1 * x0 + s2 * noise\n",
    "\n",
    "    def p_sample(self, model, x, t):\n",
    "        \"\"\"Single reverse step using ε-prediction parameterization.\"\"\"\n",
    "        betat = self.index(self.betas, t, x.shape)\n",
    "        ac_t  = self.index(self.alphas_cumprod, t, x.shape)\n",
    "        sqrt_one_minus_ac_t = self.index(self.sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
    "        eps = model(x, t)\n",
    "        x0_hat = (x - sqrt_one_minus_ac_t * eps) / torch.sqrt(ac_t)\n",
    "        mean = (1/torch.sqrt(1 - betat))*(x - betat/torch.sqrt(1 - ac_t) * eps)\n",
    "        var = self.index(self.posterior_variance, t, x.shape)\n",
    "        if (t == 0).all(): return mean\n",
    "        return mean + torch.sqrt(var) * torch.randn_like(x)\n",
    "\n",
    "    def sample(self, model, n, shape):\n",
    "        \"\"\"Draw n samples by iterating t=T-1..0.\"\"\"\n",
    "        model.eval()\n",
    "        x = torch.randn(n, *shape, device=self.device)\n",
    "        for t in reversed(range(self.n_steps)):\n",
    "            tt = torch.full((n,), t, device=self.device, dtype=torch.long)\n",
    "            with torch.no_grad():\n",
    "                x = self.p_sample(model, x, tt)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def index(a, t, x_shape):\n",
    "        return a.gather(-1, t).reshape(-1, *([1]*(len(x_shape)-1)))\n",
    "\n",
    "# # ----------------------- training script -----------------------\n",
    "# def main():\n",
    "#     \"\"\"\n",
    "#     Minimal training loop. Produces samples in ./ddpm_samples.png.\n",
    "\n",
    "#     Returns:\n",
    "#         None\n",
    "#     \"\"\"\n",
    "#     device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     T = 200\n",
    "#     bs = 128\n",
    "#     epochs = 1  # bump to 5–10 for better quality\n",
    "#     lr = 2e-4\n",
    "\n",
    "#     tfm = transforms.Compose([transforms.ToTensor(), transforms.Lambda(lambda x: x*2-1)])  # [-1,1]\n",
    "#     ds  = datasets.MNIST(root=\"./data\", train=True, download=True, transform=tfm)\n",
    "#     dl  = DataLoader(ds, batch_size=bs, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "#     net = TinyUNet(n_steps=T).to(device)\n",
    "#     diff = Diffusion(n_steps=T, device=device)\n",
    "#     opt = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "#     for epoch in range(epochs):\n",
    "#         for x,_ in dl:\n",
    "#             x = x.to(device)\n",
    "#             t = torch.randint(0, T, (x.size(0),), device=device).long()\n",
    "#             noise = torch.randn_like(x)\n",
    "#             x_t = diff.q_sample(x, t, noise)\n",
    "#             pred = net(x_t, t)\n",
    "#             loss = F.mse_loss(pred, noise)\n",
    "#             opt.zero_grad(); loss.backward(); opt.step()\n",
    "#         print(f\"epoch {epoch+1} | loss={loss.item():.4f}\")\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         imgs = diff.sample(net, n=64, shape=(1,28,28))\n",
    "#         imgs = (imgs.clamp(-1,1)+1)/2\n",
    "#     return imgs\n",
    "# #         utils.save_image(imgs, \"ddpm_samples.png\", nrow=8)\n",
    "# #     print(\"Wrote ddpm_samples.png\")\n",
    "\n",
    "# # if __name__ == \"__main__\":\n",
    "# #     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134a1ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9.91M/9.91M [00:00<00:00, 23.2MB/s]\n",
      "100%|██████████| 28.9k/28.9k [00:00<00:00, 722kB/s]\n",
      "100%|██████████| 1.65M/1.65M [00:00<00:00, 8.15MB/s]\n",
      "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.94MB/s]\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x34fd898a0>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPicklingError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m opt = torch.optim.AdamW(net.parameters(), lr=lr)\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/site-packages/torch/utils/data/dataloader.py:493\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    491\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/site-packages/torch/utils/data/dataloader.py:424\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    423\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/site-packages/torch/utils/data/dataloader.py:1171\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1164\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1170\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1171\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1173\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/popen_fork.py:20\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/popen_spawn_posix.py:47\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     46\u001b[39m     reduction.dump(prep_data, fp)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     49\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/mamba/envs/gene/lib/python3.13/multiprocessing/reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPicklingError\u001b[39m: Can't pickle <function <lambda> at 0x34fd898a0>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "T = 200 # number of diffusion steps\n",
    "bs = 128 # batch size \n",
    "epochs = 1  # bump to 5–10 for better quality\n",
    "lr = 2e-4 # learning rate\n",
    "## If torch is able to find a GPU, use it. Otherwise, use the CPU.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "ds  = datasets.MNIST(root=\"./\", train=True, download=True, transform=tfm)\n",
    "dl  = DataLoader(ds, batch_size=bs, shuffle=True, num_workers=2, drop_last=True)\n",
    "\n",
    "net = TinyUNet(n_steps=T).to(device)\n",
    "diff = Diffusion(n_steps=T, device=device)\n",
    "opt = torch.optim.AdamW(net.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for x,_ in dl:\n",
    "        x = x.to(device)\n",
    "        t = torch.randint(0, T, (x.size(0),), device=device).long()\n",
    "        noise = torch.randn_like(x)\n",
    "        x_t = diff.q_sample(x, t, noise)\n",
    "        pred = net(x_t, t)\n",
    "        loss = F.mse_loss(pred, noise)\n",
    "        opt.zero_grad(); loss.backward(); opt.step()\n",
    "    print(f\"epoch {epoch+1} | loss={loss.item():.4f}\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs = diff.sample(net, n=64, shape=(1,28,28))\n",
    "    imgs = (imgs.clamp(-1,1)+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f3ccda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e574d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d81934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc395c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75293f38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c330949c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a17281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
